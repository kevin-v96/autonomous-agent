{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(prompt='Enter OpenAI API key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key = os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature = 0,\n",
    "    model_name = \"gpt-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "tools = load_tools(\n",
    "    ['llm-math'],\n",
    "    llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent = \"zero-shot-react-description\", #zero shot: no memory, uses ReAct to decide which tool to use\n",
    "    tools = tools,\n",
    "    llm = llm,\n",
    "    verbose = True,\n",
    "    max_iterations = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to calculate the expression (3.5*114.2)^-2.4. I can use the calculator for this.\n",
      "Action: Calculator\n",
      "Action Input: (3.5*114.2)^-2.4\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 5.69951687933452e-07\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: 5.69951687933452e-07\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is (3.5*114.2)^-2.4?', 'output': '5.69951687933452e-07'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_shot_agent(\"What is (3.5*114.2)^-2.4?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "data = pd.read_csv(\"spotify-2023.csv\", encoding='latin-1')\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "\n",
    "data.to_sql('Spotify_Top_Songs_2023', engine, if_exists='replace', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "\n",
    "db = SQLDatabase(engine)\n",
    "sql_chain = SQLDatabaseChain.from_llm(llm = llm, db = db, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "sql_tool = Tool(\n",
    "    name = \"Spotify Top Songs 2023 DB\",\n",
    "    func = sql_chain.run,\n",
    "    description = \"Useful for when you need to answer questions about the Spotify top songs for 2023\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools(\n",
    "    [\"llm-math\"],\n",
    "    llm = llm\n",
    ")\n",
    "\n",
    "tools.append(sql_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversational_agent = initialize_agent(\n",
    "    agent='conversational-react-description', \n",
    "    tools=tools, \n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Spotify Top Songs 2023 DB\n",
      "Action Input: Top song artist, April 2023\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "Top song artist, April 2023\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT \"artist(s)_name\" FROM \"Spotify_Top_Songs_2023\" WHERE released_month = 4 AND released_year = 2023 ORDER BY streams DESC LIMIT 1\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('The Weeknd, Future',)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThe top song artist in April 2023 was The Weeknd, Future.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe top song artist in April 2023 was The Weeknd, Future.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: The artist with the top song on Spotify in April 2023 was The Weeknd, Future.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = conversational_agent(\n",
    "    \"Who was the artist with the top song on Spotify in April 2023?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? Yes\n",
      "Action: Spotify Top Songs 2023 DB\n",
      "Action Input: Who was the artist with the second top song in April 2023?\u001b[0m\n",
      "\n",
      "\u001b[1m> Entering new SQLDatabaseChain chain...\u001b[0m\n",
      "Who was the artist with the second top song in April 2023?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT \"artist(s)_name\" FROM \"Spotify_Top_Songs_2023\" WHERE released_month = 4 ORDER BY streams DESC LIMIT 1 OFFSET 1\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[('IU, Agust D',)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3mThe artist with the second top song in April 2023 was IU, Agust D.\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe artist with the second top song in April 2023 was IU, Agust D.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mDo I need to use a tool? No\n",
      "AI: The artist with the second top song on Spotify in April 2023 was IU, Agust D.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = conversational_agent(\n",
    "    \"Who was the artist with the second top song in the same month?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it answers question well from the SQL database. How does it do this? Let's look at the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant is a large language model trained by OpenAI.\n",
      "\n",
      "Assistant is designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, Assistant is able to generate human-like text based on the input it receives, allowing it to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
      "\n",
      "Assistant is constantly learning and improving, and its capabilities are constantly evolving. It is able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. Additionally, Assistant is able to generate its own text based on the input it receives, allowing it to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
      "\n",
      "Overall, Assistant is a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether you need help with a specific question or just want to have a conversation about a particular topic, Assistant is here to assist.\n",
      "\n",
      "TOOLS:\n",
      "------\n",
      "\n",
      "Assistant has access to the following tools:\n",
      "\n",
      "> Calculator: Useful for when you need to answer questions about math.\n",
      "> Spotify Top Songs 2023 DB: Useful for when you need to answer questions about the Spotify top songs for 2023\n",
      "\n",
      "To use a tool, please use the following format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? Yes\n",
      "Action: the action to take, should be one of [Calculator, Spotify Top Songs 2023 DB]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "```\n",
      "\n",
      "When you have a response to say to the Human, or if you do not need to use a tool, you MUST use the format:\n",
      "\n",
      "```\n",
      "Thought: Do I need to use a tool? No\n",
      "AI: [your response here]\n",
      "```\n",
      "\n",
      "Begin!\n",
      "\n",
      "Previous conversation history:\n",
      "{chat_history}\n",
      "\n",
      "New input: {input}\n",
      "{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(conversational_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import Wikipedia\n",
    "from langchain.agents.react.base import DocstoreExplorer\n",
    "\n",
    "docstore = DocstoreExplorer(Wikipedia())\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func = docstore.search,\n",
    "        description = \"search wikipedia\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Lookup\",\n",
    "        func = docstore.lookup,\n",
    "        description = \"lookup a term in wikipedia\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "docstore_agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent = \"react-docstore\",\n",
    "    verbose = True,\n",
    "    max_iterations = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to search Karl Marx and find where he is buried.\n",
      "Action: Search[Karl Marx]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mCould not find [Karl Marx]. Similar: ['Karl Marx', 'Tomb of Karl Marx', 'Karl-Marx-Allee', 'Karl Marx University', 'The Young Karl Marx', 'Karl-Marx-Hof', 'FC Erzgebirge Aue', 'Chemnitz', 'Marxism', 'Karl Marx House']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mTo find where Karl Marx is buried, I can search Tomb of Karl Marx.\n",
      "Action: Search[Tomb of Karl Marx]\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mThe Tomb of Karl Marx stands in the Eastern cemetery of Highgate Cemetery, North London, England. It commemorates the burial sites of Marx, of his wife, Jenny von Westphalen, and other members of his family. Originally buried in a different part of the Eastern cemetery, the bodies were disinterred and reburied at their present location in 1954. The tomb was designed by Laurence Bradshaw and was unveiled in 1956, in a ceremony led by Harry Pollitt, the General Secretary of the Communist Party of Great Britain, which funded the memorial.\n",
      "The tomb consists of a large bust of Marx in bronze set on a marble pedestal. The pedestal is inscribed with quotes from Marx's works including, on the front, the final words of The Communist Manifesto, \"Workers of all lands unite\". Since its construction, the tomb has become a place of pilgrimage for followers of Marxist theory. It has also been a target for Marx's opponents, suffering vandalism, and two bomb attacks in the 1970s. It is a Grade I listed structure, the highest listing reserved for buildings and structures of \"exceptional interest\".\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mKarl Marx is buried in the Eastern cemetery of Highgate Cemetery, North London, England.\n",
      "Action: Finish[Eastern cemetery of Highgate Cemetery, North London, England]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Where is Karl Marx buried?',\n",
       " 'output': 'Eastern cemetery of Highgate Cemetery, North London, England'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docstore_agent(\"Where is Karl Marx buried?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "os.environ[\"SERP_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import SerpAPIWrapper\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key = os.environ[\"SERP_API_KEY\"]) #allows searching from google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Intermediate Answer\",\n",
    "        func = search.run,\n",
    "        description = 'google search'\n",
    "    )\n",
    "]\n",
    "\n",
    "self_ask_with_search = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent = \"self-ask-with-search\",\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYes.\n",
      "Follow up: When was the theory of mind first proposed?\u001b[0m\n",
      "Intermediate answer: \u001b[36;1m\u001b[1;3m1978\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mFollow up: When was the theory of the atom first proposed?\u001b[0m\n",
      "Intermediate answer: \u001b[36;1m\u001b[1;3m5th century bce\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mFollow up: When was the theory of the cell first proposed?\u001b[0m\n",
      "Intermediate answer: \u001b[36;1m\u001b[1;3mThe classical cell theory was proposed by Theodor Schwann in 1839. There are three parts to this theory. The first part states that all organisms are made of cells.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mSo the final answer is: Theory of the atom\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What came first: Theory of mind, theory of the atom, or theory of the cell?',\n",
       " 'output': 'Theory of the atom'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_ask_with_search(\n",
    "    \"What came first: Theory of mind, theory of the atom, or theory of the cell?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our agent searches from Google and answers our question well.\n",
    "\n",
    "We can combine the multiple tools we've given our agents above to get an agent that can accomplish tasks such as:\n",
    "- Look at an SQL table\n",
    "- Look up information on Wikipedia\n",
    "- Make Google Searches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
